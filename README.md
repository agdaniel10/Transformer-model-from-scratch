# Transformer-model-from-scratch
Implementation of the Transformer model ('Attention is All You Need') from scratch using Python and NumPy/PyTorch. This project covers multi-head attention, positional encoding, and the encoder-decoder architecture, providing insights into the core principles of the Transformer model.
